{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Team:\n",
        " Javidan Hajiyev,Aziz Zeynalli"
      ],
      "metadata": {
        "id": "5V47ocuRcHk0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLWh-KsDJ7MG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "heart_data = pd.read_csv('heart.csv')\n",
        "features, target = heart_data.drop('target', axis=1), heart_data['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J9NJPHoJ7MI"
      },
      "outputs": [],
      "source": [
        "def normalize(data, mean_vals=None, std_vals=None):\n",
        "    if mean_vals is None:\n",
        "        mean_vals = np.mean(data, axis=0)\n",
        "    if std_vals is None:\n",
        "        std_vals = np.std(data, axis=0)\n",
        "    normalized_data = (data - mean_vals) / (std_vals + 1e-8)\n",
        "    return normalized_data, mean_vals, std_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_BisPPQJ7MJ"
      },
      "outputs": [],
      "source": [
        "def split_data(input_data, labels, test_fraction=0.25, seed_value=None):\n",
        "    if seed_value is not None:\n",
        "        np.random.seed(seed_value)\n",
        "\n",
        "    total_samples = len(input_data)\n",
        "    test_sample_count = int(test_fraction * total_samples)\n",
        "\n",
        "    shuffled_indices = np.arange(total_samples)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "\n",
        "    if isinstance(input_data, pd.DataFrame):\n",
        "        input_data = input_data.reset_index(drop=True).to_numpy()\n",
        "    if isinstance(labels, pd.DataFrame):\n",
        "        labels = labels.reset_index(drop=True).to_numpy()\n",
        "\n",
        "    train_data = input_data[shuffled_indices[test_sample_count:]]\n",
        "    train_labels = labels[shuffled_indices[test_sample_count:]]\n",
        "    test_data = input_data[shuffled_indices[:test_sample_count]]\n",
        "    test_labels = labels[shuffled_indices[:test_sample_count]]\n",
        "\n",
        "    return train_data, test_data, train_labels, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQGceLWWJ7MJ"
      },
      "outputs": [],
      "source": [
        "train_data, test_data, train_labels, test_labels = split_data(features, target, seed_value=42)\n",
        "train_labels, test_labels = train_labels.to_numpy(), test_labels.to_numpy()\n",
        "\n",
        "train_labels = train_labels.reshape(-1, 1)\n",
        "test_labels = test_labels.reshape(-1, 1)\n",
        "\n",
        "train_data_norm, mean_values_train, std_values_train = normalize(train_data)\n",
        "test_data_norm = normalize(test_data, mean_values_train, std_values_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJLoPoPrJ7MJ"
      },
      "outputs": [],
      "source": [
        "class MultiLayerPerceptron:\n",
        "    def __init__(self, input_dimension, hidden_layer_units, output_dimension, learning_rate):\n",
        "        self.input_dimension = input_dimension\n",
        "        self.hidden_layer_units = hidden_layer_units\n",
        "        self.output_dimension = output_dimension\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.weights_input_to_hidden = np.random.randn(self.input_dimension, self.hidden_layer_units)\n",
        "        self.weights_hidden_to_output = np.random.randn(self.hidden_layer_units, self.output_dimension)\n",
        "\n",
        "    def logistic_activation(self, input_data):\n",
        "        return 1 / (1 + np.exp(-input_data))\n",
        "\n",
        "    def logistic_derivative(self, output):\n",
        "        return output * (1 - output)\n",
        "\n",
        "    def forward_propagation(self, input_data):\n",
        "        self.input_to_hidden = np.dot(input_data, self.weights_input_to_hidden)\n",
        "        self.hidden_output = self.logistic_activation(self.input_to_hidden)\n",
        "        self.hidden_to_output = np.dot(self.hidden_output, self.weights_hidden_to_output)\n",
        "        self.final_output = self.logistic_activation(self.hidden_to_output)\n",
        "\n",
        "    def backward_propagation(self, input_data, actual_labels):\n",
        "        self.output_error = actual_labels - self.final_output\n",
        "        self.output_delta = self.output_error * self.logistic_derivative(self.final_output)\n",
        "\n",
        "        self.hidden_error = self.output_delta.dot(self.weights_hidden_to_output.T)\n",
        "        self.hidden_delta = self.hidden_error * self.logistic_derivative(self.hidden_output)\n",
        "\n",
        "        self.weights_hidden_to_output += self.hidden_output.T.dot(self.output_delta) * self.learning_rate\n",
        "        self.weights_input_to_hidden += input_data.T.dot(self.hidden_delta) * self.learning_rate\n",
        "\n",
        "    def train(self, train_data, train_labels, test_data, test_labels, num_epochs, batch_size, tolerance=1e-5):\n",
        "        self.error_history = []\n",
        "        self.epoch_history = []\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            for i in range(0, len(train_data), batch_size):\n",
        "                batch_data = train_data[i:i+batch_size]\n",
        "                batch_labels = train_labels[i:i+batch_size]\n",
        "                self.forward_propagation(batch_data)\n",
        "                self.backward_propagation(batch_data, batch_labels)\n",
        "\n",
        "            self.forward_propagation(test_data)\n",
        "            error = np.mean(np.abs(test_labels - self.final_output))\n",
        "            self.error_history.append(error)\n",
        "            self.epoch_history.append(epoch)\n",
        "\n",
        "            if epoch > 1 and np.abs(self.error_history[-1] - self.error_history[-2]) < tolerance:\n",
        "                break\n",
        "\n",
        "    def make_prediction(self, input_data):\n",
        "        self.forward_propagation(input_data)\n",
        "        return np.round(self.final_output)\n",
        "\n",
        "    def calculate_confusion_matrix(self, input_data, actual_labels):\n",
        "        predicted_labels = self.make_prediction(input_data)\n",
        "        true_positives = np.sum((predicted_labels == 1) & (actual_labels == 1))\n",
        "        false_negatives = np.sum((predicted_labels == 0) & (actual_labels == 1))\n",
        "        false_positives = np.sum((predicted_labels == 1) & (actual_labels == 0))\n",
        "        true_negatives = np.sum((predicted_labels == 0) & (actual_labels == 0))\n",
        "        return true_positives, false_negatives, false_positives, true_negatives\n",
        "\n",
        "    def calculate_precision(self, input_data, actual_labels):\n",
        "        true_positive, _, false_positive, _ = self.calculate_confusion_matrix(input_data, actual_labels)\n",
        "        return true_positive / (true_positive + false_positive) if true_positive + false_positive != 0 else 0\n",
        "\n",
        "    def calculate_accuracy(self, input_data, actual_labels):\n",
        "        true_positive, true_negative, false_positive, false_negative = self.calculate_confusion_matrix(input_data, actual_labels)\n",
        "        return (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative) if true_positive + true_negative + false_positive + false_negative != 0 else 0\n",
        "\n",
        "    def calculate_sensitivity(self, input_data, actual_labels):\n",
        "        true_positive, _, _, false_negative = self.calculate_confusion_matrix(input_data, actual_labels)\n",
        "        return true_positive / (true_positive + false_negative) if true_positive + false_negative != 0 else 0\n",
        "\n",
        "    def calculate_specificity(self, input_data, actual_labels):\n",
        "        _, true_negative, false_positive, _ = self.calculate_confusion_matrix(input_data, actual_labels)\n",
        "        return true_negative / (true_negative + false_positive) if true_negative + false_positive != 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebi92gBVJ7MK"
      },
      "outputs": [],
      "source": [
        "neural_network = MultiLayerPerceptron(input_dimension=train_data_norm.shape[1], hidden_layer_units=5, output_dimension=1, learning_rate=0.01)\n",
        "neural_network.train(train_data=train_data_norm, train_labels=train_labels, test_data=test_data_norm, test_labels=test_labels, num_epochs=1000, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXHbyt-4J7MK",
        "outputId": "e4993674-e248-4925-8048-87adea4fcf2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision is 85.36585365853658 %\n",
            "accuracy is 53.333333333333336 %\n",
            "sensitivity is 54.6875 %\n",
            "specificity is 45.45454545454545 %\n"
          ]
        }
      ],
      "source": [
        "precision = neural_network.calculate_precision(test_data_norm, test_labels)\n",
        "accuracy = neural_network.calculate_accuracy(test_data_norm, test_labels)\n",
        "sensitivity = neural_network.calculate_sensitivity(test_data_norm, test_labels)\n",
        "specificity = neural_network.calculate_specificity(test_data_norm, test_labels)\n",
        "\n",
        "print(f\"precision is {precision*100} %\")\n",
        "print(f\"accuracy is {accuracy*100} %\")\n",
        "print(f\"sensitivity is {sensitivity*100} %\")\n",
        "print(f\"specificity is {specificity*100} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5HBgit9J7MK"
      },
      "source": [
        "## DECISION TREE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR2sUXWNJ7MK"
      },
      "outputs": [],
      "source": [
        "def calculate_entropy(actual_labels):\n",
        "    histogram = np.bincount(actual_labels)\n",
        "    probabilities = histogram / len(actual_labels)\n",
        "    return -np.sum([probability * np.log2(probability) for probability in probabilities if probability > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYECSAZTJ7ML"
      },
      "outputs": [],
      "source": [
        "def calculate_confusion_matrix(actual_labels, predicted_labels):\n",
        "    true_positive = sum((actual_labels == 1) & (predicted_labels == 1))\n",
        "    true_negative = sum((actual_labels == 0) & (predicted_labels == 0))\n",
        "    false_positive = sum((actual_labels == 0) & (predicted_labels == 1))\n",
        "    false_negative = sum((actual_labels == 1) & (predicted_labels == 0))\n",
        "    return true_positive, true_negative, false_positive, false_negative\n",
        "\n",
        "def calculate_precision(actual_labels, predicted_labels):\n",
        "    true_positive, _, false_positive, _ = calculate_confusion_matrix(actual_labels, predicted_labels)\n",
        "    return true_positive / (true_positive + false_positive) if true_positive + false_positive != 0 else 0\n",
        "\n",
        "def calculate_accuracy(actual_labels, predicted_labels):\n",
        "    accuracy = np.sum(actual_labels == predicted_labels) / len(actual_labels)\n",
        "    return accuracy\n",
        "\n",
        "def calculate_sensitivity(actual_labels, predicted_labels):\n",
        "    true_positive, _, _, false_negative = calculate_confusion_matrix(actual_labels, predicted_labels)\n",
        "    return true_positive / (true_positive + false_negative) if true_positive + false_negative != 0 else 0\n",
        "\n",
        "def calculate_specificity(actual_labels, predicted_labels):\n",
        "    _, true_negative, false_positive, _ = calculate_confusion_matrix(actual_labels, predicted_labels)\n",
        "    return true_negative / (true_negative + false_positive) if true_negative + false_positive != 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLHsGBl3J7ML"
      },
      "outputs": [],
      "source": [
        "class TreeNode:\n",
        "    def __init__(self, predicted_value, index=0, cutoff=0, left_branch=None, right_branch=None):\n",
        "        self.predicted_value = predicted_value\n",
        "        self.index = index\n",
        "        self.cutoff = cutoff\n",
        "        self.left_branch = left_branch\n",
        "        self.right_branch = right_branch\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        return self.left_branch is None and self.right_branch is None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKNynkC4J7ML"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, df, target_column, test_size=0.25, min_samples=2, max_tree_depth=50, num_features=None):\n",
        "        self.df = df\n",
        "        self.target_column = target_column\n",
        "        self.test_size = test_size\n",
        "        self.min_samples = min_samples\n",
        "        self.max_tree_depth = max_tree_depth\n",
        "        self.num_features = num_features\n",
        "        self.root_node = None\n",
        "\n",
        "        self.features_train = None\n",
        "        self.features_test = None\n",
        "        self.labels_train = None\n",
        "        self.labels_test = None\n",
        "\n",
        "        self._preprocess_data()\n",
        "\n",
        "    def _preprocess_data(self):\n",
        "        x = self.df.drop(self.target_column, axis=1)\n",
        "        y = self.df[self.target_column]\n",
        "\n",
        "        indices = np.arange(x.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        split_idx = int(x.shape[0] * (1 - self.test_size))\n",
        "\n",
        "        self.features_train, self.features_test = x.iloc[indices[:split_idx], :].values, x.iloc[indices[split_idx:], :].values\n",
        "        self.labels_train, self.labels_test = y.iloc[indices[:split_idx]].values, y.iloc[indices[split_idx:]].values\n",
        "\n",
        "    def fit(self):\n",
        "        self.num_features = self.features_train.shape[1] if not self.num_features else min(self.num_features, self.features_train.shape[1])\n",
        "        self.root_node = self._grow_tree(self.features_train, self.labels_train)\n",
        "\n",
        "    def predict(self):\n",
        "        return np.array([self._traverse_tree(feature, self.root_node) for feature in self.features_test])\n",
        "\n",
        "    def _grow_tree(self, features, labels, depth=0):\n",
        "        num_samples, num_features = features.shape\n",
        "        num_labels = len(np.unique(labels))\n",
        "\n",
        "        if (depth >= self.max_tree_depth\n",
        "                or num_labels == 1\n",
        "                or num_samples < self.min_samples):\n",
        "            leaf_value = self._most_common_label(labels)\n",
        "            return TreeNode(predicted_value=leaf_value)\n",
        "\n",
        "        feature_indices = np.random.choice(num_features, self.num_features, replace=False)\n",
        "\n",
        "        best_feature, best_cutoff = self._best_criteria(features, labels, feature_indices)\n",
        "        best_cutoff = float(best_cutoff)\n",
        "\n",
        "        left_indices, right_indices = self._split(features[:, best_feature], best_cutoff)\n",
        "        left_branch = self._grow_tree(features[left_indices, :], labels[left_indices], depth+1)\n",
        "        right_branch = self._grow_tree(features[right_indices, :], labels[right_indices], depth+1)\n",
        "        return TreeNode(predicted_value=self._most_common_label(labels), index=best_feature, cutoff=best_cutoff, left_branch=left_branch, right_branch=right_branch)\n",
        "\n",
        "    def _best_criteria(self, features, labels, feature_indices):\n",
        "        best_gain = -1\n",
        "        split_index, split_cutoff = None, None\n",
        "        for feature_index in feature_indices:\n",
        "            feature_column = features[:, feature_index]\n",
        "            cutoffs = np.unique(feature_column)\n",
        "            for cutoff in cutoffs:\n",
        "                gain = self._information_gain(labels, feature_column, cutoff)\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    split_index = feature_index\n",
        "                    split_cutoff = cutoff\n",
        "\n",
        "        return split_index, split_cutoff\n",
        "\n",
        "    def _information_gain(self, labels, feature_column, split_cutoff):\n",
        "        parent_entropy = calculate_entropy(labels)\n",
        "\n",
        "        left_indices, right_indices = self._split(feature_column, split_cutoff)\n",
        "\n",
        "        if len(left_indices) == 0 or len(right_indices) == 0:\n",
        "            return 0\n",
        "\n",
        "        total = len(labels)\n",
        "        num_left, num_right = len(left_indices), len(right_indices)\n",
        "        entropy_left, entropy_right = calculate_entropy(labels[left_indices]), calculate_entropy(labels[right_indices])\n",
        "        child_entropy = (num_left / total) * entropy_left + (num_right / total) * entropy_right\n",
        "\n",
        "        info_gain = parent_entropy - child_entropy\n",
        "        return info_gain\n",
        "\n",
        "    def _split(self, feature_column, split_cutoff):\n",
        "        feature_column = np.array(feature_column)\n",
        "        left_indices = np.argwhere(feature_column <= split_cutoff).flatten()\n",
        "        right_indices = np.argwhere(feature_column > split_cutoff).flatten()\n",
        "        return left_indices, right_indices\n",
        "\n",
        "    def _traverse_tree(self, feature, node):\n",
        "        if node.is_leaf_node():\n",
        "            return node.predicted_value\n",
        "\n",
        "        if feature[node.index] <= node.cutoff:\n",
        "            return self._traverse_tree(feature, node.left_branch)\n",
        "        return self._traverse_tree(feature, node.right_branch)\n",
        "\n",
        "    def _most_common_label(self, labels):\n",
        "        counter = Counter(labels)\n",
        "        most_common = counter.most_common(1)[0][0]\n",
        "        return most_common"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qAQvmcVJ7ML"
      },
      "outputs": [],
      "source": [
        "tree = DecisionTree(df=heart_data, target_column='target', max_tree_depth=3)\n",
        "\n",
        "tree.fit()\n",
        "\n",
        "predicted_labels = tree.predict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVMxKfl0J7MM",
        "outputId": "8dc97ff0-907c-40dd-da05-d950fbf41b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision is 82.97872340425532 %\n",
            "accuracy is 86.8421052631579 %\n",
            "sensitivity is 95.1219512195122 %\n",
            "specificity is 77.14285714285715 %\n"
          ]
        }
      ],
      "source": [
        "accuracy_score = calculate_accuracy(tree.labels_test, predicted_labels)\n",
        "precision_score = calculate_precision(tree.labels_test, predicted_labels)\n",
        "sensitivity_score = calculate_sensitivity(tree.labels_test, predicted_labels)\n",
        "specificity_score = calculate_specificity(tree.labels_test, predicted_labels)\n",
        "\n",
        "print(f\"precision is {precision_score*100} %\")\n",
        "print(f\"accuracy is {accuracy_score*100} %\")\n",
        "print(f\"sensitivity is {sensitivity_score*100} %\")\n",
        "print(f\"specificity is {specificity_score*100} %\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}